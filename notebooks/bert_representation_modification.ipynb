{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Dependecies**"
      ],
      "metadata": {
        "id": "-Gz1E_NhM4aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import BertModel, BertTokenizer"
      ],
      "metadata": {
        "id": "QoYUCxR2IVcG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Common Setup Functions**\n"
      ],
      "metadata": {
        "id": "DR142SFMJA2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_model_and_tokenizer(model_name='bert-base-uncased'):\n",
        "    model = BertModel.from_pretrained(model_name)\n",
        "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "    return model, tokenizer\n",
        "\n",
        "def prepare_inputs(text, tokenizer):\n",
        "    return tokenizer(text, return_tensors='pt')\n",
        "\n",
        "def create_additional_input_vector(hidden_size):\n",
        "    return torch.randn(1, 1, hidden_size)"
      ],
      "metadata": {
        "id": "ktrThlBFJBGl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Common Integration Method Apllier**"
      ],
      "metadata": {
        "id": "X7NybcvAHoub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IntegrationMethodApplier(nn.Module):\n",
        "    def __init__(self, integration_method):\n",
        "        super(IntegrationMethodApplier, self).__init__()\n",
        "        self.integration_method = integration_method\n",
        "\n",
        "    def forward(self, input_tensor, additional_input_vector):\n",
        "        if self.integration_method == \"addition\":\n",
        "            return input_tensor + additional_input_vector\n",
        "        elif self.integration_method == \"multiplication\":\n",
        "            return input_tensor * additional_input_vector\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported integration method\")"
      ],
      "metadata": {
        "id": "hqhdm7g-I96m"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hook-Based Approach**"
      ],
      "metadata": {
        "id": "SpdvxrQxH8Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define the HookBasedBERTModifier**"
      ],
      "metadata": {
        "id": "du6cBOikOfZI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KPCanM-K_m_6"
      },
      "outputs": [],
      "source": [
        "class HookBasedBERTModifier:\n",
        "    def __init__(self, model, layer_number, integration_method_applier):\n",
        "        self.model = model\n",
        "        self.layer_number = layer_number\n",
        "        self.integration_method_applier = integration_method_applier\n",
        "        self.hook = None\n",
        "\n",
        "    def modify_input(self, module, input):\n",
        "        input_tensor = input[0]\n",
        "        modified_input = self.integration_method_applier(input_tensor, self.additional_input_vector)\n",
        "        return (modified_input,)\n",
        "\n",
        "    def register_hook(self, additional_input_vector):\n",
        "        self.additional_input_vector = additional_input_vector\n",
        "        layer = self.model.encoder.layer[self.layer_number - 1]\n",
        "        self.hook = layer.register_forward_pre_hook(self.modify_input)\n",
        "\n",
        "    def remove_hook(self):\n",
        "        if self.hook is not None:\n",
        "            self.hook.remove()\n",
        "            self.hook = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test Hook-Based Approach**"
      ],
      "metadata": {
        "id": "1xjPs1KXLr3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_hook_based_modifier(input_text, layer_number, integration_method):\n",
        "    model, tokenizer = setup_model_and_tokenizer()\n",
        "    additional_input_vector = create_additional_input_vector(model.config.hidden_size)\n",
        "    integration_method_applier = IntegrationMethodApplier(integration_method)\n",
        "\n",
        "    modifier = HookBasedBERTModifier(model, layer_number, integration_method_applier)\n",
        "\n",
        "    inputs = prepare_inputs(input_text, tokenizer)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs_without_hook = model(**inputs)\n",
        "\n",
        "    modifier.register_hook(additional_input_vector)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs_with_hook = model(**inputs)\n",
        "\n",
        "    modifier.remove_hook()\n",
        "\n",
        "    output_difference = torch.abs(outputs_with_hook.last_hidden_state - outputs_without_hook.last_hidden_state)\n",
        "    print(\"Output difference: \", torch.sum(output_difference).item())\n",
        "    # return outputs_without_hook, outputs_with_hook"
      ],
      "metadata": {
        "id": "gbPB1hbeK0Te"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run The Test**"
      ],
      "metadata": {
        "id": "4kxehbsZLzTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_hook_based_modifier(\"Hello, how are you?\", 10, \"multiplication\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbhQEpc3J7sB",
        "outputId": "3e30c30a-670a-4ac0-b083-b635f3c1288f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output difference:  3657.418212890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Layer-Based Approach**\n"
      ],
      "metadata": {
        "id": "L74Aq4AcIBb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define the CustomLayerBERTModifier**"
      ],
      "metadata": {
        "id": "LiTepkdTOcil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLayerBERTModifier(nn.Module):\n",
        "    def __init__(self, model, layer_number, integration_method_applier):\n",
        "\n",
        "        super(CustomLayerBERTModifier, self).__init__()\n",
        "        self.bert = model\n",
        "        self.layer_number = layer_number\n",
        "        self.integration_method_applier = integration_method_applier\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, additional_input_vector):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states\n",
        "        modified_layer_input = self.integration_method_applier(hidden_states[self.layer_number - 1], additional_input_vector)\n",
        "        for i in range(self.layer_number, len(self.bert.encoder.layer)):\n",
        "            modified_layer_input = self.bert.encoder.layer[i](modified_layer_input)[0]\n",
        "\n",
        "        return modified_layer_input\n"
      ],
      "metadata": {
        "id": "pmfrzbTlDF_N"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Test Custom Layer-Based Approach**"
      ],
      "metadata": {
        "id": "MaoY0dGaMxpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_custom_layer_modifier(input_text, layer_number, integration_method):\n",
        "    model, tokenizer = setup_model_and_tokenizer()\n",
        "\n",
        "    additional_input_vector = create_additional_input_vector(model.config.hidden_size)\n",
        "\n",
        "    integration_method_applier = IntegrationMethodApplier(integration_method)\n",
        "    custom_model = CustomLayerBERTModifier(model, layer_number, integration_method_applier)\n",
        "\n",
        "    inputs = prepare_inputs(input_text, tokenizer)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = custom_model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], additional_input_vector=additional_input_vector)\n",
        "\n",
        "    print(\"Output shape: \", outputs.shape)\n",
        "    # return outputs"
      ],
      "metadata": {
        "id": "1vR3xFL_MBdV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Run The Test**"
      ],
      "metadata": {
        "id": "2GHimnBaMsM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_custom_layer_modifier(\"Hello, how are you?\", 10, \"addition\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2km8deJmMkcX",
        "outputId": "4fc3add4-610c-46f1-ff51-4102bfda83ed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape:  torch.Size([1, 8, 768])\n"
          ]
        }
      ]
    }
  ]
}